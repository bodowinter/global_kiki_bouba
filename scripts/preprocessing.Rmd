---
title: "Preprocessing Data: Online Experiment"
author: "Bodo Winter"
date: "7/30/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is the preprocessing script that cleans the data from the online and the field work experiment. The main data is from the vocal iconicity challenge and we need to extract the kiki/bouba data.

## Load in data

Load packages:

```{r, message = FALSE}
library(tidyverse)
```

Load in online data:

```{r, message = FALSE, warning = FALSE}
# Get vector with list of all files:

all_files <- list.files('../data/online/')

# Create an empty object which will be grown with all the files:

web <- c()
for (i in seq_along(all_files)) {
  this_file <- str_c('../data/online/', all_files[i])
  this_file <- read_delim(this_file, delim = '\t')
  web <- rbind(web, this_file)
}
```

Get only those that have "kiki.wav" and "bouba.wav" as files.

```{r}
web <- filter(web, audio %in% c('kiki.wav', 'bouba.wav'))
```

How much data do we have per experiment? (divide by two because of two data points per participant)

```{r}
table(web$experiment) / 2
```

Languages are stored in the format "AL", "EN" etc. Let's process the "experiment" column so that it has only those strings:

```{r}
web <- mutate(web,
              Language = str_extract(experiment, '[A-Z]{2,2}'))
```

Just in case some session IDs recur across the different experiments, let's create a unique identifier column by pasting languages and session IDs together:

```{r}
web <- mutate(web,
              ID = str_c(Language, '_', session))
```

## Exclusions:

Exclude those that have 'l1' == 'q' which is Ola's code for her own test runs.

```{r}
web <- filter(web,
              l1 != 'q')
web <- filter(web,
              firstlanguage != 'q')
```

Check number of playbacks:

```{r}
table(web$playbacks)
```

Exclude 0 playbacks (didn't listen to the sound):

```{r}
web <- filter(web, playbacks != 0)
```

Check ages:

```{r}
table(web$participantage)
```

Get rid of everybody below 18:

```{r}
web <- filter(web, participantage >= 18)
```

Check input values:

```{r}
table(web$inputvalue)
```

Get rid of the responses that are neither "kiki" nor "bouba", and likewise for "r" and "l":

```{r}
web <- filter(web, !inputvalue %in% c('jeść', 'wąż'))
```

## Process L1 information:

Create a table with one data point per participant with L2 information:

```{r}
L2_info <- filter(web, !duplicated(ID)) %>% select(ID, Language, l1, l2)
```

Get rid of trailing spaces:

```{r}
L2_info <- mutate(L2_info,
                  l1 = str_trim(l1))
```

That one Chinese person who wrote "hi" in the language field probably knows English given that they used this word... this is the more conservative choice (working against our hypothesis):

```{r}
L2_info[L2_info$l1 == 'hi', ]$l1 <- 'chinese'
L2_info[which(L2_info$l2 == 'hi'), ]$l2 <- 'english'
```

Perform replacements — for this, we take whatever is the person's first-listed language as their primary L1 (this only applies to a few cases anyway). In a few cases where there is overlap with another language of which we have multile speakers in the sample, the assignment will be done this way, e.g., "ukrainian, russian" -> "russian"

```{r}
L2_info <- mutate(L2_info,
                  l1 = str_replace(l1, 'isizulu', 'zulu'),
                  l1 = str_replace(l1, 'turkce', 'turkish'),
                  l1 = str_replace(l1, 'swedish, korean', 'swedish'),
                  l1 = str_replace(l1, 'french, spanish', 'french'),
                  l1 = str_replace(l1, 'ukrainian, russian', 'russian'),
                  l1 = str_replace(l1, 'portuguese, french, danish', 'portuguese'),
                  l1 = str_replace(l1, 'finnish, estonian', 'finnish'),
                  l1 = str_replace(l1, 'albanianja', 'albanian'),
                  l1 = str_replace(l1, 'armenian, russian', 'armenian'),
                  l1 = str_replace(l1, 'swissgerman', 'german'),
                  l1 = str_replace(l1, 'austriangerman', 'german'),
                  l1 = str_replace(l1, 'german, turkish', 'german'),
                  l1 = str_replace(l1, 'german, english', 'german'),
                  l1 = str_replace(l1, 'konkani, english', 'english'),
                  l1 = str_replace(l1, 'español', 'spanish'),
                  l1 = str_replace(l1, 'spanish, german', 'spanish'),
                  l1 = str_replace(l1, 'italian, german', 'italian'),
                  l1 = str_replace(l1, 'italian, german', 'italian'),
                  l1 = str_replace(l1, 'italia', 'italian'),                  
                  l1 = str_replace(l1, 'italiann', 'italian'),
                  l1 = str_replace(l1, 'polish, silesian', 'polish'),
                  l1 = str_replace(l1, 'swedish, finnish', 'swedish'),
                  l1 = str_replace(l1, 'greek, german', 'greek'),
                  l1 = str_replace(l1, 'russian, belarusian', 'russian'),
                  l1 = str_replace(l1, 'georgian, mingrelian', 'georgian'),
                  l1 = str_replace(l1, 'hi', 'chinese'),
                  l1 = str_replace(l1, 'cchinesenese', 'chinese'))
```

## Process L2 information:

Transform NAs into "this person knows no L2":

```{r}
L2_info <- mutate(L2_info,
                  l2 = ifelse(is.na(l2), 'no_L2', l2))
```

Extract whether the person reports any English:

```{r}
L2_info <- mutate(L2_info,
                  EnglishL2YesNo = str_detect(l2, 'english'))
```

Conversions:

```{r}
L2_info <- mutate(L2_info,
                  l2 = str_replace(l2, 'potuguese', 'portuguese'),
                  l2 = str_replace(l2, 'spanich', 'spanish'),
                  l2 = str_replace(l2, 'calatan', 'catalan'),
                  l2 = str_replace(l2, 'ancient greek', 'greek'),
                  l2 = str_replace(l2, 'rumanian', 'romanian'),
                  l2 = str_replace(l2, 'estniska', 'estonian'),
                  l2 = str_replace(l2, 'calabrese', 'italian'),
                  l2 = str_replace(l2, 'dari', 'farsi'))
```

Get all languages spoken:

```{r}
all_L2s <- str_replace_all(L2_info$l2, "(a little bit )|(a little )", "")
all_L2s <- unlist(str_split(all_L2s, "(, )|(,)|(，)|(\\.)|( )"))
all_L2s <- str_trim(all_L2s)
all_L2s <- sort(unique(all_L2s))
all_L2s <- all_L2s[!all_L2s %in% c("", "no_L2")]

# Print:

all_L2s
```

Put into table and match script as well as whether they are IE:

```{r}
L2_lang_info <- tibble(L2 = all_L2s)
```

Fill in script info:

```{r}
# For reference:

 # c("afrikaans", "arabic", "armenian", "asl", "basque", "bulgarian",
 #  "catalan", "chinese", "creole", "croatian", "czech", "danish",
 #  "dutch", "english", "esperanto", "estonian", "farsi", "finnish",
 #  "french", "georgian", "german", "greek", "hebrew", 
 #  "hindi", "hungarian", "icelandic", "indonesian", "irish", "italian", 
 #  "japanese", "korean", "latin", "latvian", "limburgish", "macedonian",
 #  "nepali", "NGT", "norwegian", "polish", "portuguese", "romanian",
 #  "russian", "saami", "sanskrit", "serbian", "slovak", "sotho",
 #  "spanish", "swahili", "swazi", "swedish", "tamil", "turkish",
 #  "vietnamese", "xhosa")

L2_lang_info$L2_script <- c("roman", "other script", "other script", "not script", "roman", "other script",
  "roman", "other script", "roman", "roman", "roman", "roman",
  "roman", "roman", "roman", "roman", "other script", "roman",
  "roman", "other script", "roman", "other script", "other script",
  "other script", "roman", "roman", "other script", "roman", "roman",
  "other script", "other script", "roman", "roman", "roman", "other script",
  "other script", "no script", "roman", "roman", "roman", "roman",
  "other script", "roman", "other script", "other script", "roman", "roman",
  "roman", "roman", "roman", "roman", "other script", "roman",
  "roman", "roman")

# Serbian is counted as "other" because of cyrillic despite digraphia

```

Fill in IE info:

```{r}
L2_lang_info$L2_IE <- c("IE", "not IE", "IE", "not IE", "not IE", "IE",
  "IE", "not IE", "not IE", "IE", "IE", "IE",
  "IE", "IE", "IE", "not IE", "not IE", "not IE",
  "IE", "not IE", "IE", "IE", "not IE",
  "IE", "not IE", "IE", "not IE", "IE", "IE",
  "not IE", "not IE", "IE", "IE", "IE", "IE",
  "IE", "not IE", "IE", "IE", "IE", "IE",
  "IE", "not IE", "IE", "IE", "IE", "not IE",
  "IE", "not IE", "not IE", "IE", "not IE", "not IE",
  "not IE", "not IE")
```

Get big regular expressions out of those that have roman script:

```{r}
# IE:

IE_regex <- str_c(filter(L2_lang_info, L2_IE == 'IE')$L2,
                  collapse = '|')

# Script:

roman_regex <- str_c(filter(L2_lang_info, L2_script == 'roman')$L2,
                     collapse = '|')
```

Create variables based on that for all speakers. First, whether they know at least one language that has a roman alphabet:

```{r}
L2_info <- mutate(L2_info,
                  RomanScriptL2 = str_detect(l2, roman_regex),
                  IEL2 = str_detect(l2, IE_regex))
```

Match this with the "web" data frame:

```{r}
web <- left_join(web, select(L2_info, -Language), by = c('ID' = 'ID'))
```

Rename:

```{r}
web <- rename(web,
              L1_raw = l1.x,
              L2_raw = l2.x,
              L1_cleaned = l1.y,
              L2_cleaned = l2.y)
```

## Exclusions based on insufficient data:

How much data per language?

```{r}
table(web$Language)
```

How many data per participant?

```{r}
ppt_N <- web %>% count(ID)
```

Check whether there's anybody who doesn't have 2 responses?

```{r}
all(ppt_N$n == 2)
```

Which one?

```{r}
filter(ppt_N, n != 2)
```

Get rid of these participants:

```{r}
# Vector of participants to exclude:

excludes <- filter(ppt_N, n != 2) %>% pull(ID)

# Exclude:

web <- filter(web, !(ID %in% excludes))
```

Count data per language again:

```{r}
web %>% count(Language) %>% 
  mutate(n = n / 2) %>% 
  print(n = Inf)
```

Not enough data for MS (only data from one speaker), as well as Tamil (only two speakers):

```{r}
web <- filter(web, Language != "MS")
web <- filter(web, Language != "TA")
```

Get rid of L1 speakers that differ from the sample they are supposed to belong to:

```{r}
web <- filter(web,
              !L1_cleaned %in% c('arabic', 'zhuang', 'esperanto',
                                 'kurdish', 'pashto',
                                 'wolof'))

# Close enough for our purposes from the perspective of kiki/bouba and the fact that language families don't cross — sorry if you are a speaker of one of these languages as we recognize the difference, but the most important thing is that these do not exert a bias from a "macro perspective" of language families:

web[web$L1_cleaned == 'catalan', ]$L1_cleaned <- 'spanish'
web[web$L1_cleaned == 'finnish', ]$L1_cleaned <- 'estonian'
web[web$L1_cleaned == 'dutch', ]$L1_cleaned <- 'german'
web[web$L1_cleaned == 'czech', ]$L1_cleaned <- 'polish'
web[web$L1_cleaned == 'latvian', ]$L1_cleaned <- 'polish'
```

Check which ones are misaligned:

```{r}
table(web$L1_cleaned, web$Language)
web[web$L1_cleaned == 'russian', ]$Language <- 'RU'
web[web$L1_cleaned == 'armenian', ]$Language <- 'AM'
web[web$L1_cleaned == 'chinese', ]$Language <- 'CN'
web[web$L1_cleaned == 'english', ]$Language <- 'EN'
web[web$L1_cleaned == 'estonian', ]$Language <- 'EE'
web[web$L1_cleaned == 'german', ]$Language <- 'DE'
web[web$L1_cleaned == 'french', ]$Language <- 'FR'
web[web$L1_cleaned == 'italian', ]$Language <- 'IT'
web[web$L1_cleaned == 'korean', ]$Language <- 'KR'
web[web$L1_cleaned == 'polish', ]$Language <- 'PL'
web[web$L1_cleaned == 'zulu', ]$Language <- 'ZU'
web[web$L1_cleaned == 'spanish', ]$Language <- 'ES'
web[web$L1_cleaned == 'swedish', ]$Language <- 'SE'
web[web$L1_cleaned == 'portuguese', ]$Language <- 'PT'
web[web$L1_cleaned == 'thai', ]$Language <- 'TH'
```


## Add language info:

Load language file:

```{r, message = FALSE}
langs <- read_csv('../data/language_info.csv')
```

Merge:

```{r}
web <- left_join(web, langs)
```


## Create response variable

Change main response to "Resp":

```{r}
web <- rename(web,
               Resp = inputvalue)
```

Let's process the main predictor (the audio file shown):

```{r}
web <- mutate(web,
              Condition = str_replace(audio, '\\.wav', ''),
              Condition = str_to_title(Condition))
```

## By-participant preprocessing

Arguably, the responses to "kiki" and "bouba", since they immediately followed each other, are not independent. 

Let's create a file of matching versus non-matching participants. First, create a vector of Condition/Resp contingency tables broken up by participant:

```{r}
ID_tabs <- with(web, table(Condition, Resp, ID))
```

Loop through this and save whether they were 100% matching:

```{r}
matches <- numeric(dim(ID_tabs)[3])

for (i in seq_along(matches)) {
  matches[i] <- as.integer(sum(diag(ID_tabs[, , i])) == 2)
}
```

Put this together with ID info into a table:

```{r}
ids <- unique(web$ID)
kiki_ppt <- tibble(ID = ids, Match = matches)
```

Merge this with the relevant info:

```{r}
kiki_ppt$Language <- web[match(kiki_ppt$ID, web$ID), ]$Language
kiki_ppt$Name <- web[match(kiki_ppt$ID, web$ID), ]$Name
kiki_ppt$Script <- web[match(kiki_ppt$ID, web$ID), ]$Script
kiki_ppt$Family <- web[match(kiki_ppt$ID, web$ID), ]$Family
kiki_ppt$Autotyp_Area <- web[match(kiki_ppt$ID, web$ID), ]$Autotyp_Area
kiki_ppt$L2 <- web[match(kiki_ppt$ID, web$ID), ]$L2_raw
kiki_ppt$EnglishL2YesNo <- web[match(kiki_ppt$ID, web$ID), ]$EnglishL2YesNo
kiki_ppt$RomanScriptL2 <- web[match(kiki_ppt$ID, web$ID), ]$RomanScriptL2
kiki_ppt$IEL2 <- web[match(kiki_ppt$ID, web$ID), ]$IEL2
```

Write to file:

```{r}
write_csv(kiki_ppt, '../data/web_experiment_cleaned.csv')
```

## Fieldwork data:

Get the fieldwork data:

```{r, message = FALSE}
field <- read_delim('../data/kiki_fieldwork.csv',
                    delim = ';')
```

The field response file is wide format. Let's transform this to long format:

```{r}
field <- gather(field, 'ID', 'Choice', -file)
```

Get the language info out of the ID column:

```{r}
field <- mutate(field,
                Language = str_extract(ID, '[A-Z]+'))
```

Get rid of the r and l experiment part:

```{r}
field <- filter(field,
                !(file %in% c('r', 'l')))
```

Get rid of those that have choice == 0.

```{r}
field <- filter(field,
                Choice != 0)
```

Check whether all participants have the same amount of data:

```{r}
ppt_N <- field %>% count(ID)

all(ppt_N$n == 2)
```

Yes, they do.

Separate the info about whether the stimulus was "kiki" or "bouba", and whether the delivery was "auditory" or "orthographic".

```{r}
field <- separate(field, file, into = c('Condition', 'Modality'))
```

Check how many there are per language:

```{r}
table(field$Language)
```

Get rid of "PL" and "EN" (only 2 data points):

```{r}
field <- filter(field,
                !(Language %in% c('EN', 'PL')))
```

Check distribution of languages across conditions:

```{r}
with(field, table(Language, Modality))
```

Create a file where the matches are stored:

```{r}
all_IDs <- unique(field$ID)
orts <- rep(NA, length(all_IDs))
auds <- rep(NA, length(all_IDs))
for (i in seq_along(all_IDs)) {
  this_df <- filter(field, ID == all_IDs[i])
  
  if (any(this_df$Modality == 'aud')) {
    this_auds <- filter(this_df, Modality == 'aud')
    this_auds <- with(this_auds, table(Condition, Choice))
    auds[i] <- as.integer(sum(diag(this_auds)) == 2)
  }

  if (any(this_df$Modality == 'ort')) {
    this_orts <- filter(this_df, Modality == 'ort')
    this_orts <- with(this_orts, table(Condition, Choice))
    orts[i] <- as.integer(sum(diag(this_orts)) == 2)
  }  
}
```

Put this into a tibble:

```{r}
field_ppt <- tibble(ID = all_IDs, Ort = orts, Aud = auds)
```

Make this into a long format:

```{r}
field_ppt <- gather(field_ppt, key = 'Modality', value = 'Match', -ID)
```

Add the language information:

```{r}
field_ppt$Language <- field[match(field_ppt$ID, field$ID), ]$Language
```

## The first five participants in the field experiment have been wrongly coded:

Email from Ola Feb 10, 2020 indicates that the first five participants in the German data of the field experiment have been erroneously coded as mismatches (0), even though they were matches:

```{r}
these_ppts <- str_c('DE0', 1:5)
field_ppt[field_ppt$ID %in% these_ppts & !is.na(field_ppt$Match), ]$Match <- 1
```

Write this:

```{r}
write_csv(field_ppt, '../data/field_experiment_cleaned.csv')
```